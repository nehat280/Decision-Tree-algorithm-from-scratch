{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import random \n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  label\n",
       "0       3    male  22.0      1      0   7.2500        S      0\n",
       "1       1  female  38.0      1      0  71.2833        C      1\n",
       "2       3  female  26.0      0      0   7.9250        S      1\n",
       "3       1  female  35.0      1      0  53.1000        S      1\n",
       "4       3    male  35.0      0      0   8.0500        S      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('titanic.csv')\n",
    "df[\"label\"]=df.Survived\n",
    "df = df.drop([\"Name\",\"Ticket\",\"Cabin\",\"Survived\",\"PassengerId\"],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    object \n",
      " 2   Age       714 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  889 non-null    object \n",
      " 7   label     891 non-null    int64  \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # to check if null is present \n",
    "\n",
    "# as can see age and Embarked need Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    object \n",
      " 2   Age       891 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  891 non-null    object \n",
      " 7   label     891 non-null    int64  \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "Age_median = df.Age.median()\n",
    "Embarked_mode = df.Embarked.mode()[0] \n",
    "df.Age.fillna(value=Age_median, inplace=True)\n",
    "df.Embarked.fillna(value=Embarked_mode, inplace=True)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,test_size):\n",
    "    ## to check if test_size is passed as proportion or a number\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(len(df)*test_size) \n",
    "    ##\n",
    "    indices=df.index.tolist()\n",
    "    test_indices=random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked  label\n",
      "864       2    male  24.0      0      0   13.0000        S      0\n",
      "394       3  female  24.0      0      2   16.7000        S      1\n",
      "776       3    male  28.0      0      0    7.7500        Q      0\n",
      "430       1    male  28.0      0      0   26.5500        S      1\n",
      "41        2  female  27.0      1      0   21.0000        S      0\n",
      "265       2    male  36.0      0      0   10.5000        S      0\n",
      "523       1  female  44.0      0      1   57.9792        C      1\n",
      "497       3    male  28.0      0      0   15.1000        S      0\n",
      "414       3    male  44.0      0      0    7.9250        S      1\n",
      "802       1    male  11.0      1      2  120.0000        S      1\n",
      "849       1  female  28.0      1      0   89.1042        C      1\n",
      "310       1  female  24.0      0      0   83.1583        C      1\n",
      "488       3    male  30.0      0      0    8.0500        S      0\n",
      "366       1  female  60.0      1      0   75.2500        C      1\n",
      "597       3    male  49.0      0      0    0.0000        S      0\n",
      "223       3    male  28.0      0      0    7.8958        S      0\n",
      "516       2  female  34.0      0      0   10.5000        S      1\n",
      "142       3  female  24.0      1      0   15.8500        S      1\n",
      "288       2    male  42.0      0      0   13.0000        S      1\n",
      "143       3    male  19.0      0      0    6.7500        Q      0\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df , test_size=20)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity( data ):\n",
    "    label_column = data[:,-1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_purity(train_df[train_df.petal_width <0.8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[train_df. petal_width > 0.8].values[-1]  # function will take only the last column in label_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):  # retrurn the class of label by taking np dataset\n",
    "    label_column = data[:,-1]\n",
    "    # here we have to incluse 2 functionalities\n",
    "    # if datapoints are less than 5 points then return the class that appears most often\n",
    "    # if labels within dataset is pure return leaf node\n",
    "    unique_classes, count_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index = count_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify_data(train_df[train_df.petal_width > 0.8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify_data(train_df[(train_df.petal_width >0.8) & (train_df.petal_width < 2) ].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    potential_splits={ }\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "        potential_splits[column_index] = [] \n",
    "        values = data[: , column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[column_index]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            if  len (unique_values) > 1:\n",
    "                for index in  range(len(unique_values)):\n",
    "                    if index != 0:\n",
    "                        current_value = unique_values[index]\n",
    "                        previous_value = unique_values[index -1 ]\n",
    "                        potential_split = (current_value + previous_value)/2\n",
    "\n",
    "                        potential_splits[column_index].append(potential_split)\n",
    "\n",
    "        elif len (unique_values) > 1:\n",
    "            potential_splits[column_index] = unique_values\n",
    "            \n",
    "\n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FEATURE_TYPES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1df418b16026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpotential_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_potential_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpotential_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a162340ad3ab>\u001b[0m in \u001b[0;36mget_potential_splits\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0munique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtype_of_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFEATURE_TYPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_of_feature\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"continuous\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m  \u001b[0mlen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FEATURE_TYPES' is not defined"
     ]
    }
   ],
   "source": [
    "potential_splits = get_potential_splits(train_df.values)\n",
    "potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TYPES = feature_type\n",
    "FEATURE_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column , split_value):\n",
    "    split_column_values=data[:, split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values<= split_value]\n",
    "        data_above= data[split_column_values >split_value]\n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above= data[split_column_values != split_value]\n",
    "        \n",
    "\n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_column=1\n",
    "split_value= \"male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_below, data_above = split_data(data, split_column, split_value)\n",
    "print(np.unique(data_below[:,1]))\n",
    "print(np.unique(data_above[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest overall entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    label_column = data[:, -1]\n",
    "    _,counts = np.unique(label_column,return_counts=True)  # count is vector\n",
    "    \n",
    "    probabilities = counts/ counts.sum() # count is vector\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below)/ n_data_points\n",
    "    p_data_above = len(data_above) / n_data_points\n",
    "    \n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)) + (p_data_above * calculate_entropy(data_above))\n",
    "    return overall_entropy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    overall_entropy=999  # some highest impossible value\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data( data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy<= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    \n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits=get_potential_splits(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the type of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_type = []\n",
    "    n_unique_values_threshold = 15   # if unique value<15 then its categorical\n",
    "    \n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        example_value = df[column].unique()[0]\n",
    "        if isinstance(example_value, str) or len(unique_values) <= n_unique_values_threshold:\n",
    "            feature_type.append(\"categorical\")\n",
    "        else:\n",
    "            feature_type.append(\"Continuous\")\n",
    "            \n",
    "        \n",
    "    return feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = determine_type_of_feature(df)\n",
    "i=0\n",
    "for column in range(len(feature_type)):\n",
    "    print(column ,feature_type[i])\n",
    "    i+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## representation of Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d45afe1396e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mquestion\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_answer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "subtree = {question : [yes_answer, no_answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-342817bf7383>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-342817bf7383>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    'virginica'\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "example_tree ={'petal_width <=0.8':[\"setosa\",\n",
    "                                    {'petal_width<=1.65':[{'petal_length <=4.9':['versicolor',\n",
    "                                                                                 'virginica']}\n",
    "                                                          'virginica'\n",
    "                                                         ]\n",
    "                                    }\n",
    "                                   ]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depths=5):  # df is a data frame\n",
    "    # dataframe converted to numpy array\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS , FEATURE_TYPE\n",
    "        COLUMN_HEADERS=df.columns\n",
    "        FEATURE_TYPE = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # base case \n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depths ):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    else:\n",
    "        counter +=1\n",
    "        \n",
    "        #helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        \n",
    "        if len(potential_splits) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        split_column ,split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column , split_value)\n",
    "        \n",
    "        #instantiate sub-tree\n",
    "        feature_name =COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        else:\n",
    "            question = \"{} == {}\".format(feature_name, split_value)\n",
    "        subtree = {question :[]}\n",
    "        \n",
    "        # find answers(recursion)\n",
    "        \n",
    "        yes_answer = decision_tree_algorithm(data_below , counter, min_samples,max_depths)\n",
    "        no_answer = decision_tree_algorithm(data_above , counter, min_samples, max_depths)\n",
    "        if yes_answer == no_answer:\n",
    "            subtree = yes_answer\n",
    "        else:\n",
    "            subtree[question].append(yes_answer)\n",
    "            subtree[question].append(no_answer)\n",
    "\n",
    "        return subtree\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'determine_type_of_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-493d9016e753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#here the leafs at last depth were same \"virginica\" hence we  removed that subtrree and instead just append the leaf to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-37f5d4460622>\u001b[0m in \u001b[0;36mdecision_tree_algorithm\u001b[1;34m(df, counter, min_samples, max_depths)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0mCOLUMN_HEADERS\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mFEATURE_TYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mCOLUMN_HEADERS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mFEATURE_TYPE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_type_of_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'determine_type_of_feature' is not defined"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df,max_depths=3)\n",
    "pprint(tree, width=50)\n",
    "\n",
    "#here the leafs at last depth were same \"virginica\" hence we  removed that subtrree and instead just append the leaf to\n",
    "#parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question=list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "    #ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <=float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:        # categorical values within data gave tyoe str\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):  # if answer is not a dict i.e. it is int, float, char \n",
    "        return answer\n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer      # else send the remaining subtree \n",
    "        return classify_example(example,residual_tree)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass            1\n",
      "Sex          female\n",
      "Age              28\n",
      "SibSp             1\n",
      "Parch             0\n",
      "Fare        89.1042\n",
      "Embarked          C\n",
      "label             1\n",
      "Name: 849, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a6bde92bc447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[10]\n",
    "print(example)\n",
    "pprint(classify_example(example, tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass           3\n",
      "Sex         female\n",
      "Age             24\n",
      "SibSp            0\n",
      "Parch            2\n",
      "Fare          16.7\n",
      "Embarked         S\n",
      "label            1\n",
      "Name: 394, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-084c87893a24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "example=test_df.iloc[1]\n",
    "print(example)\n",
    "pprint(classify_example(example,tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df,tree):\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = (df.classification == df.label) # will return boolean T or F\n",
    "    \n",
    "    accuracy = df.classification_correct.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'determine_type_of_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ac9060d61762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-37f5d4460622>\u001b[0m in \u001b[0;36mdecision_tree_algorithm\u001b[1;34m(df, counter, min_samples, max_depths)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0mCOLUMN_HEADERS\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mFEATURE_TYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mCOLUMN_HEADERS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mFEATURE_TYPE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_type_of_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'determine_type_of_feature' is not defined"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df , test_size=20)\n",
    "tree = decision_tree_algorithm(train_df,max_depths=3)\n",
    "accuracy= calculate_accuracy(test_df,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
